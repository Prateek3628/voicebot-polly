<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Voice Assistant - TechGropse</title>
    <script src="https://cdn.socket.io/4.7.2/socket.io.min.js"></script>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', 'Helvetica Neue', Arial, sans-serif;
            background: #000000;
            min-height: 100vh;
            display: flex;
            align-items: center;
            justify-content: center;
            padding: 0;
            overflow: hidden;
        }

        .container {
            width: 100%;
            height: 100vh;
            display: flex;
            align-items: center;
            justify-content: center;
        }

        .voice-interface {
            background: transparent;
            border-radius: 0;
            padding: 0;
            box-shadow: none;
            text-align: center;
            width: 100%;
        }

        h1 {
            color: white;
            margin-bottom: 10px;
            font-size: 28px;
            display: none;
        }

        .subtitle {
            color: white;
            margin-bottom: 30px;
            font-size: 14px;
            display: none;
        }

        .connection-status {
            position: fixed;
            top: 20px;
            left: 20px;
            padding: 8px 16px;
            border-radius: 50%;
            font-size: 12px;
            font-weight: bold;
            width: 40px;
            height: 40px;
            display: flex;
            align-items: center;
            justify-content: center;
            z-index: 1000;
        }

        .connected {
            background-color: rgba(255, 255, 255, 0.1);
            color: white;
            border: 1px solid rgba(255, 255, 255, 0.2);
        }

        .disconnected {
            background-color: rgba(255, 255, 255, 0.1);
            color: white;
            border: 1px solid rgba(255, 255, 255, 0.2);
        }

        /* Voice Button */
        .voice-button {
            width: 200px;
            height: 200px;
            border-radius: 50%;
            border: none;
            background: radial-gradient(circle at center, rgba(0, 145, 255, 0.8) 0%, rgba(0, 100, 200, 0.6) 50%, rgba(0, 50, 120, 0.4) 100%);
            color: rgba(0, 180, 255, 0.9);
            font-size: 64px;
            cursor: pointer;
            transition: all 0.3s ease;
            box-shadow: 0 0 80px rgba(0, 145, 255, 0.6), 0 0 120px rgba(0, 145, 255, 0.4), inset 0 0 40px rgba(0, 145, 255, 0.3);
            margin: 0 auto;
            display: flex;
            align-items: center;
            justify-content: center;
            position: relative;
            overflow: visible;
        }

        /* Wave effects */
        .voice-button::before,
        .voice-button::after {
            content: '';
            position: absolute;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            width: 100%;
            height: 100%;
            border-radius: 50%;
            border: 2px solid rgba(0, 145, 255, 0.4);
            animation: wave 2s ease-out infinite;
            pointer-events: none;
        }

        .voice-button::after {
            animation-delay: 1s;
        }

        @keyframes wave {
            0% {
                transform: translate(-50%, -50%) scale(1);
                opacity: 0.8;
            }

            100% {
                transform: translate(-50%, -50%) scale(1.8);
                opacity: 0;
            }
        }

        .voice-button:hover:not(:disabled) {
            transform: scale(1.05);
            box-shadow: 0 0 100px rgba(0, 145, 255, 0.8), 0 0 140px rgba(0, 145, 255, 0.5), inset 0 0 50px rgba(0, 145, 255, 0.4);
        }

        .voice-button:active:not(:disabled) {
            transform: scale(0.98);
        }

        .voice-button:disabled {
            opacity: 0.5;
            cursor: not-allowed;
        }

        .voice-button.recording {
            background: radial-gradient(circle at center, rgba(0, 180, 255, 0.9) 0%, rgba(0, 145, 255, 0.7) 50%, rgba(0, 100, 200, 0.5) 100%);
            animation: pulse 1.5s ease-in-out infinite;
            box-shadow: 0 0 100px rgba(0, 145, 255, 0.8), 0 0 160px rgba(0, 145, 255, 0.6), inset 0 0 50px rgba(0, 145, 255, 0.4);
        }

        .voice-button.speaking {
            background: radial-gradient(circle at center, rgba(0, 145, 255, 0.8) 0%, rgba(0, 100, 200, 0.6) 50%, rgba(0, 50, 120, 0.4) 100%);
            animation: wobble 0.6s ease-in-out infinite;
            box-shadow: 0 0 80px rgba(0, 145, 255, 0.6), 0 0 120px rgba(0, 145, 255, 0.4), inset 0 0 40px rgba(0, 145, 255, 0.3);
        }

        .voice-button.speaking::before,
        .voice-button.speaking::after {
            animation: wave 1.5s ease-out infinite;
        }

        .voice-button.speaking::after {
            animation-delay: 0.75s;
        }

        @keyframes pulse {

            0%,
            100% {
                transform: scale(1);
                box-shadow: 0 0 100px rgba(0, 145, 255, 0.8), 0 0 160px rgba(0, 145, 255, 0.6), inset 0 0 50px rgba(0, 145, 255, 0.4);
            }

            50% {
                transform: scale(1.05);
                box-shadow: 0 0 120px rgba(0, 145, 255, 1), 0 0 180px rgba(0, 145, 255, 0.8), inset 0 0 60px rgba(0, 145, 255, 0.5);
            }
        }

        @keyframes wobble {

            0%,
            100% {
                transform: rotate(0deg) scale(1);
            }

            25% {
                transform: rotate(-3deg) scale(1.02);
            }

            75% {
                transform: rotate(3deg) scale(1.02);
            }
        }

        .status-text {
            color: rgba(255, 255, 255, 0.9);
            font-size: 18px;
            margin-top: 60px;
            min-height: 24px;
            font-weight: 300;
            letter-spacing: 0.5px;
            transition: opacity 0.3s ease;
        }

        .status-text.hidden {
            opacity: 0;
        }

        .transcription {
            background: transparent;
            border-radius: 10px;
            padding: 15px;
            margin: 20px 0;
            min-height: 60px;
            color: rgba(255, 255, 255, 0.7);
            font-style: italic;
            display: none;
            position: fixed;
            top: 80px;
            left: 50%;
            transform: translateX(-50%);
            max-width: 80%;
        }

        .transcription.show {
            display: block;
        }

        /* Chatbox - Hidden by default, shown when collecting info */
        .chatbox {
            background: rgba(15, 15, 15, 0.7);
            border-radius: 20px;
            padding: 20px;
            margin-top: 30px;
            max-height: 350px;
            overflow-y: auto;
            display: none;
            transition: all 0.4s ease;
            position: fixed;
            bottom: 30px;
            left: 50%;
            transform: translateX(-50%);
            width: 85%;
            max-width: 450px;
            backdrop-filter: blur(20px);
            border: 1px solid rgba(255, 255, 255, 0.05);
            box-shadow: 0 8px 32px rgba(0, 0, 0, 0.5);
        }

        .chatbox.show {
            display: block;
            animation: slideInUp 0.4s ease;
        }

        @keyframes slideInUp {
            from {
                opacity: 0;
                transform: translate(-50%, 20px);
            }

            to {
                opacity: 1;
                transform: translate(-50%, 0);
            }
        }

        .chatbox::-webkit-scrollbar {
            width: 6px;
        }

        .chatbox::-webkit-scrollbar-track {
            background: rgba(255, 255, 255, 0.05);
            border-radius: 10px;
        }

        .chatbox::-webkit-scrollbar-thumb {
            background: rgba(255, 255, 255, 0.15);
            border-radius: 10px;
        }

        .chatbox::-webkit-scrollbar-thumb:hover {
            background: rgba(255, 255, 255, 0.25);
        }

        .chatbox-header {
            font-weight: 400;
            color: rgba(255, 255, 255, 0.6);
            margin-bottom: 15px;
            font-size: 12px;
            text-transform: uppercase;
            letter-spacing: 1px;
        }

        .message {
            margin-bottom: 10px;
            padding: 10px 14px;
            border-radius: 16px;
            text-align: left;
            font-size: 14px;
            line-height: 1.4;
            animation: messageSlideIn 0.3s ease;
        }

        @keyframes messageSlideIn {
            from {
                opacity: 0;
                transform: translateY(10px);
            }

            to {
                opacity: 1;
                transform: translateY(0);
            }
        }

        .user-message {
            background-color: rgba(0, 145, 255, 0.3);
            color: rgba(255, 255, 255, 0.95);
            margin-left: 15%;
            border: 1px solid rgba(0, 145, 255, 0.2);
        }

        .bot-message {
            background-color: rgba(255, 255, 255, 0.05);
            color: rgba(255, 255, 255, 0.85);
            margin-right: 15%;
            border: 1px solid rgba(255, 255, 255, 0.08);
        }

        .input-area {
            display: flex;
            gap: 10px;
            margin-top: 15px;
        }

        .input-area input {
            flex: 1;
            padding: 12px 16px;
            border: 1px solid rgba(255, 255, 255, 0.1);
            border-radius: 20px;
            font-size: 14px;
            background: rgba(255, 255, 255, 0.05);
            color: rgba(255, 255, 255, 0.9);
            outline: none;
            transition: all 0.3s ease;
        }

        .input-area input:focus {
            border-color: rgba(0, 145, 255, 0.4);
            background: rgba(255, 255, 255, 0.08);
        }

        .input-area input::placeholder {
            color: rgba(255, 255, 255, 0.4);
        }

        .input-area button {
            padding: 12px 24px;
            background: linear-gradient(135deg, rgba(0, 145, 255, 0.6), rgba(0, 100, 200, 0.6));
            color: white;
            border: none;
            border-radius: 20px;
            cursor: pointer;
            font-size: 14px;
            transition: all 0.3s ease;
            border: 1px solid rgba(0, 145, 255, 0.3);
        }

        .input-area button:hover {
            background: linear-gradient(135deg, rgba(0, 180, 255, 0.7), rgba(0, 145, 255, 0.7));
            transform: translateY(-1px);
            box-shadow: 0 4px 12px rgba(0, 145, 255, 0.3);
        }

        .input-area button:active {
            transform: translateY(0);
        }

        .audio-indicator {
            display: none;
            color: rgba(255, 255, 255, 0.7);
            font-size: 14px;
            margin-top: 15px;
            position: fixed;
            top: 80px;
            left: 50%;
            transform: translateX(-50%);
        }

        .audio-indicator.show {
            display: block;
        }

        .help-text {
            color: rgba(255, 255, 255, 0.5);
            font-size: 14px;
            margin-top: 0;
            position: fixed;
            bottom: 40px;
            left: 50%;
            transform: translateX(-50%);
            font-weight: 300;
        }

        /* Voice Selector */
        .voice-selector-btn {
            position: fixed;
            top: 20px;
            right: 20px;
            width: 40px;
            height: 40px;
            border-radius: 50%;
            background: rgba(255, 255, 255, 0.1);
            border: 1px solid rgba(255, 255, 255, 0.2);
            color: white;
            font-size: 20px;
            cursor: pointer;
            display: flex;
            align-items: center;
            justify-content: center;
            transition: all 0.3s ease;
            z-index: 1000;
        }

        .voice-selector-btn:hover {
            background: rgba(255, 255, 255, 0.15);
            transform: scale(1.05);
        }

        .voice-modal {
            display: none;
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background: rgba(0, 0, 0, 0.8);
            backdrop-filter: blur(10px);
            z-index: 2000;
            align-items: center;
            justify-content: center;
        }

        .voice-modal.show {
            display: flex;
        }

        .voice-modal-content {
            background: rgba(20, 20, 20, 0.95);
            border-radius: 20px;
            padding: 30px;
            max-width: 500px;
            width: 90%;
            border: 1px solid rgba(255, 255, 255, 0.1);
            animation: modalSlideIn 0.3s ease;
        }

        @keyframes modalSlideIn {
            from {
                opacity: 0;
                transform: translateY(-20px);
            }

            to {
                opacity: 1;
                transform: translateY(0);
            }
        }

        .voice-modal-header {
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 20px;
        }

        .voice-modal-title {
            color: white;
            font-size: 20px;
            font-weight: 500;
        }

        .voice-modal-close {
            background: none;
            border: none;
            color: rgba(255, 255, 255, 0.6);
            font-size: 24px;
            cursor: pointer;
            padding: 0;
            width: 30px;
            height: 30px;
            display: flex;
            align-items: center;
            justify-content: center;
            border-radius: 50%;
            transition: all 0.3s ease;
        }

        .voice-modal-close:hover {
            background: rgba(255, 255, 255, 0.1);
            color: white;
        }

        .voice-category {
            margin-bottom: 25px;
        }

        .voice-category-title {
            color: rgba(255, 255, 255, 0.7);
            font-size: 14px;
            text-transform: uppercase;
            letter-spacing: 1px;
            margin-bottom: 12px;
            font-weight: 500;
        }

        .voice-options {
            display: grid;
            grid-template-columns: repeat(auto-fill, minmax(100px, 1fr));
            gap: 10px;
        }

        .voice-option {
            background: rgba(255, 255, 255, 0.05);
            border: 1px solid rgba(255, 255, 255, 0.1);
            border-radius: 12px;
            padding: 12px;
            color: rgba(255, 255, 255, 0.8);
            cursor: pointer;
            transition: all 0.3s ease;
            text-align: center;
            font-size: 14px;
        }

        .voice-option:hover {
            background: rgba(255, 255, 255, 0.1);
            border-color: rgba(0, 145, 255, 0.4);
            transform: translateY(-2px);
        }

        .voice-option.selected {
            background: rgba(0, 145, 255, 0.3);
            border-color: rgba(0, 145, 255, 0.6);
            color: white;
        }

        .current-voice {
            color: rgba(255, 255, 255, 0.5);
            font-size: 12px;
            text-align: center;
            margin-top: 15px;
        }
    </style>
</head>

<body>
    <div class="container">
        <div class="voice-interface">
            <h1>üé§ Voice Assistant</h1>
            <p class="subtitle">TechGropse Virtual Representative</p>

            <div id="connectionStatus" class="connection-status disconnected">
                Connecting...
            </div>

            <!-- Voice Selector Button -->
            <button id="voiceSelectorBtn" class="voice-selector-btn" title="Change Voice">
                ‚öôÔ∏è
            </button>

            <button id="voiceButton" class="voice-button" disabled>
                üé§
            </button>

            <div id="statusText" class="status-text">
                Please provide your information
            </div>

            <div id="transcription" class="transcription">
                <strong>You said:</strong> <span id="transcriptionText"></span>
            </div>

            <div id="audioIndicator" class="audio-indicator" style="display: none;">
            </div>

            <!-- Chatbox - Only shown when collecting contact info -->
            <div id="chatbox" class="chatbox">
                <div class="chatbox-header">Contact Details</div>
                <div id="chatMessages"></div>
                <div class="input-area">
                    <input type="text" id="chatInput" placeholder="Type here...">
                    <button id="chatSend">Send</button>
                </div>
            </div>

        </div>
    </div>

    <!-- Voice Selection Modal -->
    <div id="voiceModal" class="voice-modal">
        <div class="voice-modal-content">
            <div class="voice-modal-header">
                <div class="voice-modal-title">Select Voice</div>
                <button id="closeVoiceModal" class="voice-modal-close">√ó</button>
            </div>

            <div class="voice-category">
                <div class="voice-category-title">üë® Male Voices</div>
                <div class="voice-options" id="maleVoices"></div>
            </div>

            <div class="voice-category">
                <div class="voice-category-title">üë© Female Voices</div>
                <div class="voice-options" id="femaleVoices"></div>
            </div>

            <div class="current-voice" id="currentVoice">Current: Salli</div>
        </div>
    </div>

    <script>
        // Initialize Socket.IO connection
        const socket = io('http://0.0.0.0:5000');

        // DOM elements
        const voiceButton = document.getElementById('voiceButton');
        const statusText = document.getElementById('statusText');
        const transcription = document.getElementById('transcription');
        const transcriptionText = document.getElementById('transcriptionText');
        const connectionStatus = document.getElementById('connectionStatus');
        const audioIndicator = document.getElementById('audioIndicator');
        const chatbox = document.getElementById('chatbox');
        const chatMessages = document.getElementById('chatMessages');
        const chatInput = document.getElementById('chatInput');
        const chatSend = document.getElementById('chatSend');

        // Voice selector elements
        const voiceSelectorBtn = document.getElementById('voiceSelectorBtn');
        const voiceModal = document.getElementById('voiceModal');
        const closeVoiceModal = document.getElementById('closeVoiceModal');
        const maleVoicesContainer = document.getElementById('maleVoices');
        const femaleVoicesContainer = document.getElementById('femaleVoices');
        const currentVoiceDisplay = document.getElementById('currentVoice');

        // Current voice state
        let currentVoice = 'Salli';
        let availableVoices = { male: [], female: [] };

        // Audio recording
        let mediaRecorder = null;
        let audioChunks = [];
        let isRecording = false;
        let mediaStream = null; // Persistent media stream
        let isListening = false; // Track if mic is actively listening
        let silenceTimeout = null;
        let silenceDelay = 2000; // 2 seconds of silence before auto-sending

        // Audio playback
        let audioContext = null;
        let nextPlayTime = 0;
        let isPlayingAudio = false;
        let activeSources = [];
        let isFirstChunk = true;
        
        // Chatbox state
        let isChatboxActive = false;
        
        // User info collection state
        let userInfoCollected = false;

        // Initialize audio context
        async function initAudioContext() {
            if (!audioContext) {
                audioContext = new (window.AudioContext || window.webkitAudioContext)();
                console.log('Audio context initialized');
            }
        }

        // Initialize microphone access (called once on connection)
        async function initMicrophone() {
            try {
                if (!mediaStream) {
                    mediaStream = await navigator.mediaDevices.getUserMedia({ audio: true });
                    console.log('Microphone access granted');
                }
            } catch (error) {
                console.error('Error accessing microphone:', error);
                statusText.textContent = 'Microphone access denied';
                voiceButton.disabled = true;
            }
        }

        // Start recording with auto-stop on silence
        async function startRecording() {
            try {
                // Don't allow recording if chatbox is active
                if (isChatboxActive) {
                    console.log('Chatbox is active, microphone disabled');
                    return;
                }

                // INTERRUPT: Stop any ongoing AI speech when user starts speaking
                if (isPlayingAudio || activeSources.length > 0) {
                    console.log('Interrupting AI speech - user is speaking');
                    stopAllAudio();
                }

                // Ensure microphone is initialized
                if (!mediaStream) {
                    await initMicrophone();
                    if (!mediaStream) return; // Failed to get microphone
                }

                mediaRecorder = new MediaRecorder(mediaStream, { mimeType: 'audio/webm' });
                audioChunks = [];

                mediaRecorder.ondataavailable = (event) => {
                    audioChunks.push(event.data);
                };

                mediaRecorder.onstop = async () => {
                    const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
                    await sendAudioToServer(audioBlob);
                    // Don't stop the stream - keep it for next recording
                };

                // Start recording with small chunks to enable silence detection
                mediaRecorder.start(100); // Record in 100ms chunks
                isRecording = true;
                isListening = true;
                voiceButton.classList.add('recording');
                voiceButton.textContent = 'üé§';
                statusText.textContent = 'Listening...';
                console.log('Recording started with auto-detection');
                
                // Start silence detection
                startSilenceDetection();
            } catch (error) {
                console.error('Error starting recording:', error);
                statusText.textContent = 'Error: Microphone access denied';
            }
        }
        
        // Detect silence and auto-stop recording
        function startSilenceDetection() {
            if (!mediaStream) return;
            
            const audioContext = new (window.AudioContext || window.webkitAudioContext)();
            const analyser = audioContext.createAnalyser();
            const microphone = audioContext.createMediaStreamSource(mediaStream);
            const dataArray = new Uint8Array(analyser.frequencyBinCount);
            
            microphone.connect(analyser);
            analyser.fftSize = 2048;
            
            let silenceStart = Date.now();
            let isSpeaking = false;
            
            function checkAudioLevel() {
                if (!isRecording) {
                    audioContext.close();
                    return;
                }
                
                analyser.getByteTimeDomainData(dataArray);
                
                // Calculate volume
                let sum = 0;
                for (let i = 0; i < dataArray.length; i++) {
                    const normalized = (dataArray[i] - 128) / 128;
                    sum += normalized * normalized;
                }
                const volume = Math.sqrt(sum / dataArray.length);
                
                // Threshold for speech detection (adjust as needed)
                const speechThreshold = 0.02;
                
                if (volume > speechThreshold) {
                    // Speech detected
                    isSpeaking = true;
                    silenceStart = Date.now();
                } else if (isSpeaking) {
                    // Check if silence duration exceeds threshold
                    const silenceDuration = Date.now() - silenceStart;
                    if (silenceDuration > silenceDelay) {
                        console.log('Silence detected, auto-stopping recording');
                        stopRecording();
                        audioContext.close();
                        return;
                    }
                }
                
                requestAnimationFrame(checkAudioLevel);
            }
            
            checkAudioLevel();
        }

        // Stop recording
        function stopRecording() {
            if (mediaRecorder && isRecording) {
                mediaRecorder.stop();
                isRecording = false;
                isListening = false;
                voiceButton.classList.remove('recording');
                statusText.textContent = 'Processing...';
                console.log('Recording stopped');
            }
        }
        
        // Interrupt AI and start recording
        function interruptAI() {
            if (isPlayingAudio) {
                console.log('User interrupted AI');
                stopAllAudio();
                // Start recording immediately after interrupt
                setTimeout(() => {
                    if (!isChatboxActive) {
                        startRecording();
                    }
                }, 100);
            }
        }

        // Send audio to server
        async function sendAudioToServer(audioBlob) {
            try {
                // Check if audio blob has sufficient data
                // Minimum size check to avoid sending empty/corrupted audio
                if (audioBlob.size < 1000) {  // Less than 1KB is likely too short
                    console.log('Audio too short, skipping transcription');
                    statusText.textContent = 'Recording too short, please try again';
                    voiceButton.disabled = false;
                    
                    // Don't auto-restart after short recording
                    return;
                }

                // Convert blob to base64
                const reader = new FileReader();
                reader.onloadend = () => {
                    const base64Audio = reader.result.split(',')[1];
                    socket.emit('voice_input', {
                        audio: base64Audio,
                        format: 'webm'
                    });
                };
                reader.readAsDataURL(audioBlob);
            } catch (error) {
                console.error('Error sending audio:', error);
                statusText.textContent = 'Error sending audio';
            }
        }

        // Audio playback for MP3
        let audioChunksBuffer = [];
        let currentAudio = null;

        // Play audio chunk (MP3 format)
        async function playAudioChunk(base64Data) {
            try {
                // Add chunk to buffer
                audioChunksBuffer.push(base64Data);
            } catch (error) {
                console.error('Error buffering audio:', error);
            }
        }

        // Play complete MP3 audio
        async function playCompleteAudio() {
            if (audioChunksBuffer.length === 0) return;

            try {
                // Combine all chunks
                const binaryStrings = audioChunksBuffer.map(chunk => atob(chunk));
                const totalLength = binaryStrings.reduce((acc, str) => acc + str.length, 0);

                const arrayBuffer = new Uint8Array(totalLength);
                let offset = 0;

                for (const binaryString of binaryStrings) {
                    for (let i = 0; i < binaryString.length; i++) {
                        arrayBuffer[offset++] = binaryString.charCodeAt(i);
                    }
                }

                // Create blob and play
                const blob = new Blob([arrayBuffer], { type: 'audio/mpeg' });
                const audioUrl = URL.createObjectURL(blob);

                currentAudio = new Audio(audioUrl);
                currentAudio.play();

                currentAudio.onended = () => {
                    URL.revokeObjectURL(audioUrl);
                    currentAudio = null;
                    isPlayingAudio = false;
                    voiceButton.textContent = 'üé§';
                    voiceButton.classList.remove('speaking');
                    statusText.classList.remove('hidden');
                    voiceButton.disabled = false;
                    
                    // Auto-enable microphone after AI finishes speaking (if chatbox not active)
                    if (!isChatboxActive && userInfoCollected) {
                        statusText.textContent = 'Listening...';
                        // Automatically start listening again
                        setTimeout(() => {
                            if (!isRecording && !isChatboxActive && !isPlayingAudio) {
                                startRecording();
                            }
                        }, 500);
                    } else if (isChatboxActive) {
                        statusText.textContent = 'Type your response';
                    }
                };

                currentAudio.onerror = (e) => {
                    console.error('Audio playback error:', e);
                    URL.revokeObjectURL(audioUrl);
                    currentAudio = null;
                    isPlayingAudio = false;
                };

            } catch (error) {
                console.error('Error playing complete audio:', error);
                isPlayingAudio = false;
            }
        }

        // Stop all audio
        function stopAllAudio() {
            // Stop current audio if playing
            if (currentAudio) {
                currentAudio.pause();
                currentAudio.currentTime = 0;
                currentAudio = null;
            }

            // Clear buffer
            audioChunksBuffer = [];

            isPlayingAudio = false;
            audioIndicator.classList.remove('show');

            // Reset UI
            voiceButton.textContent = 'üé§';
            voiceButton.classList.remove('speaking');
            voiceButton.disabled = false;
            statusText.classList.remove('hidden');
            
            if (!isChatboxActive && userInfoCollected) {
                statusText.textContent = 'Listening...';
            } else if (isChatboxActive) {
                statusText.textContent = 'Type your response';
            }

            console.log('All audio stopped');
        }

        // Add message to chatbox
        function addChatMessage(content, type = 'bot') {
            const messageDiv = document.createElement('div');
            messageDiv.className = `message ${type}-message`;
            messageDiv.textContent = content;
            chatMessages.appendChild(messageDiv);
            chatMessages.scrollTop = chatMessages.scrollHeight;
        }

        // Send text message (for chatbox)
        function sendTextMessage() {
            const message = chatInput.value.trim();
            if (!message) return;

            // Stop any ongoing audio playback when user sends a new message
            if (isPlayingAudio || activeSources.length > 0) {
                console.log('Stopping audio - user submitted new text message');
                stopAllAudio();
            }

            // Stop recording if active
            if (isRecording) {
                stopRecording();
            }

            addChatMessage(message, 'user');
            socket.emit('text_query', { text: message });
            chatInput.value = '';
        }

        // Voice button event listeners - Only for interruption
        voiceButton.addEventListener('click', () => {
            console.log('Button clicked - Is playing:', isPlayingAudio);
            if (isPlayingAudio) {
                interruptAI();
            }
        });

        // Chat input listeners
        chatSend.addEventListener('click', sendTextMessage);
        chatInput.addEventListener('keypress', (e) => {
            if (e.key === 'Enter') {
                sendTextMessage();
            }
        });
        
        // Monitor when chatbox input is focused (disable mic)
        chatInput.addEventListener('focus', () => {
            console.log('Chat input focused - disabling microphone');
            isChatboxActive = true;
            if (isRecording) {
                stopRecording();
            }
        });
        
        // Re-enable mic when chatbox loses focus and is hidden
        chatInput.addEventListener('blur', () => {
            // Check if chatbox is still visible
            setTimeout(() => {
                if (!chatbox.classList.contains('show')) {
                    console.log('Chatbox hidden - re-enabling microphone');
                    isChatboxActive = false;
                }
            }, 100);
        });

        // Voice selector functions
        function loadVoices() {
            socket.emit('get_voices');
        }

        function renderVoiceOptions() {
            // Render male voices
            maleVoicesContainer.innerHTML = '';
            availableVoices.male.forEach(voice => {
                const voiceBtn = document.createElement('div');
                voiceBtn.className = 'voice-option';
                if (voice === currentVoice) {
                    voiceBtn.classList.add('selected');
                }
                voiceBtn.textContent = voice;
                voiceBtn.onclick = () => selectVoice(voice);
                maleVoicesContainer.appendChild(voiceBtn);
            });

            // Render female voices
            femaleVoicesContainer.innerHTML = '';
            availableVoices.female.forEach(voice => {
                const voiceBtn = document.createElement('div');
                voiceBtn.className = 'voice-option';
                if (voice === currentVoice) {
                    voiceBtn.classList.add('selected');
                }
                voiceBtn.textContent = voice;
                voiceBtn.onclick = () => selectVoice(voice);
                femaleVoicesContainer.appendChild(voiceBtn);
            });

            currentVoiceDisplay.textContent = `Current: ${currentVoice}`;
        }

        function selectVoice(voiceId) {
            console.log('Selecting voice:', voiceId);
            socket.emit('change_voice', { voice_id: voiceId });
        }

        // Voice selector event listeners
        voiceSelectorBtn.addEventListener('click', () => {
            voiceModal.classList.add('show');
            loadVoices();
        });

        closeVoiceModal.addEventListener('click', () => {
            voiceModal.classList.remove('show');
        });

        voiceModal.addEventListener('click', (e) => {
            if (e.target === voiceModal) {
                voiceModal.classList.remove('show');
            }
        });

        // Socket event handlers
        socket.on('connect', async () => {
            console.log('Connected to server');
            connectionStatus.textContent = '‚úÖ';
            connectionStatus.className = 'connection-status connected';

            // Initialize microphone on connection
            await initMicrophone();

            voiceButton.disabled = false;
            statusText.textContent = 'Please provide your information';
            
            // Show chatbox initially for user info
            // Wait for server to trigger chatbox display
            console.log('Ready - waiting for user info collection');
        });

        socket.on('disconnect', () => {
            console.log('Disconnected from server');
            connectionStatus.textContent = '‚ùå';
            connectionStatus.className = 'connection-status disconnected';
            voiceButton.disabled = true;
            statusText.textContent = 'Disconnected';

            // Stop recording if active
            if (isRecording) {
                stopRecording();
            }

            // Clean up media stream on disconnect
            if (mediaStream) {
                mediaStream.getTracks().forEach(track => track.stop());
                mediaStream = null;
            }
        });

        socket.on('transcription_start', (data) => {
            console.log('Transcription starting');
            statusText.textContent = 'Transcribing...';
            // Keep button visible but not recording
            voiceButton.classList.remove('recording');
        });

        socket.on('transcription_complete', (data) => {
            console.log('Transcription:', data.text);
            // Don't show transcription - pure voice mode
            // transcriptionText.textContent = data.text;
            // transcription.classList.add('show');
            statusText.textContent = 'üí≠ Thinking...';
        });

        socket.on('text_response', (data) => {
            console.log('Response:', data);
            // Don't show text response - pure voice mode
            // statusText.textContent = data.message;

            // Handle chatbox visibility based on flag
            if (data.show_chatbox) {
                console.log('Showing chatbox - collecting:', data.current_field);
                isChatboxActive = true;
                userInfoCollected = false;
                // Stop recording when chatbox appears
                if (isRecording) {
                    stopRecording();
                }
                chatbox.classList.add('show');
                addChatMessage(data.message, 'bot');
                chatInput.focus();
            } else {
                console.log('Hiding chatbox - normal conversation');
                isChatboxActive = false;
                chatbox.classList.remove('show');
                
                // Mark that user info has been collected
                if (!userInfoCollected) {
                    userInfoCollected = true;
                    // Auto-start recording after user info is collected
                    setTimeout(() => {
                        if (!isRecording && !isPlayingAudio) {
                            console.log('User info collected, auto-starting recording');
                            startRecording();
                        }
                    }, 500);
                }
            }
        });

        socket.on('audio_start', (data) => {
            console.log('Audio starting');
            isPlayingAudio = true;

            // Clear previous audio buffer
            audioChunksBuffer = [];

            // Change to interrupt button
            voiceButton.textContent = '‚è∏Ô∏è';
            voiceButton.classList.add('speaking');
            voiceButton.classList.remove('recording');

            // Show interrupt message
            statusText.classList.remove('hidden');
            statusText.textContent = 'Click to interrupt';
        });

        socket.on('audio_chunk', async (data) => {
            if (isPlayingAudio) {
                await playAudioChunk(data.data);
            }
        });

        socket.on('audio_end', async (data) => {
            console.log('Audio ended, playing buffered MP3 audio');

            // Play the complete buffered audio
            await playCompleteAudio();

            // Note: UI updates are handled in playCompleteAudio's onended callback
        });

        socket.on('error', (data) => {
            console.error('Error:', data);
            statusText.textContent = `Error: ${data.message}`;
            voiceButton.disabled = false;

            // Reset status after a delay
            setTimeout(() => {
                statusText.textContent = 'Hold to speak';
            }, 3000);
        });

        // Voice selection event handlers
        socket.on('available_voices', (data) => {
            console.log('Received available voices:', data.voices);
            availableVoices = data.voices;
            renderVoiceOptions();
        });

        socket.on('voice_changed', (data) => {
            console.log('Voice changed:', data);
            currentVoice = data.voice_id;
            currentVoiceDisplay.textContent = `Current: ${currentVoice}`;
            renderVoiceOptions();

            // Show brief confirmation
            const prevText = statusText.textContent;
            statusText.textContent = `Voice changed to ${currentVoice}`;
            setTimeout(() => {
                if (statusText.textContent.includes('Voice changed')) {
                    statusText.textContent = prevText;
                }
            }, 2000);
        });

        // Initialize audio context on first interaction
        document.addEventListener('click', initAudioContext);
    </script>
</body>

</html>